{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MockUI Jupyter notebook to prototyping the LP-application using Plotly Dash\n",
    "\n",
    "* Scope of prototyping  \n",
    "  - Fetching input data from Excel\n",
    "  - Fetching results data from GAMS .gdx-file \n",
    "  - Visualizing input and results data using Plotly Express\n",
    "  - Setting up web application using Dash components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\23-4002-LPTool\\App\\MockUI\n",
      "C:\\anaconda3\n",
      "c:\\anaconda3\\envs\\mbl\\python311.zip\n",
      "c:\\anaconda3\\envs\\mbl\\DLLs\n",
      "c:\\anaconda3\\envs\\mbl\\Lib\n",
      "c:\\anaconda3\\envs\\mbl\n",
      "\n",
      "C:\\Users\\MogensBechLaursen\\AppData\\Roaming\\Python\\Python311\\site-packages\n",
      "c:\\anaconda3\\envs\\mbl\\Lib\\site-packages\n",
      "c:\\anaconda3\\envs\\mbl\\Lib\\site-packages\\win32\n",
      "c:\\anaconda3\\envs\\mbl\\Lib\\site-packages\\win32\\lib\n",
      "c:\\anaconda3\\envs\\mbl\\Lib\\site-packages\\Pythonwin\n",
      "Timestamp: 2024-01-10 09:46:13\n",
      "plotly------------------------v5.18.0\n",
      "dash--------------------------v2.14.2\n",
      "dash.dcc----------------------v2.12.1\n",
      "dash.html---------------------v2.0.15\n",
      "dash_bootstrap_components-----v1.5.0\n",
      "pandas------------------------v2.1.4\n",
      "numpy-------------------------v1.24.3\n",
      "xlwings-----------------------v0.29.1\n"
     ]
    }
   ],
   "source": [
    "from typing import IO, Any\n",
    "import sys\n",
    "import os\n",
    "import logging\n",
    "import shutil\n",
    "import locale\n",
    "import time\n",
    "import datetime as dt\n",
    "from datetime import datetime, timedelta\n",
    "import asyncio\n",
    "from venv import create\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import pyxlsb\n",
    "import xlwings as xw\n",
    "import GdxWrapper as gw\n",
    "import gams.transfer as gtr\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import dash\n",
    "from dash import Dash, html, dash_table, dcc, Output, Input, State\n",
    "import dash_bootstrap_components as dbc\n",
    "from dash.exceptions import PreventUpdate\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "appPath = r'C:\\\\GitHub\\\\23-4002-LPTool\\\\App'\n",
    "if not appPath in sys.path:\n",
    "    sys.path = [] + sys.path\n",
    "print('\\n'.join(sys.path))\n",
    "\n",
    "from lpBase import LpBase, JobResultKind\n",
    "LpBase.setAppRootPath(appPath)\n",
    "logger = LpBase.initLogger('MecLpTool')\n",
    "\n",
    "print(f'Timestamp: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
    "for p in [plotly, dash, dcc, html, dbc, pd, np, xw]:\n",
    "    print(f'{p.__name__:-<30}v{p.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StemData():\n",
    "\n",
    "    _logger = LpBase.getLogger()\n",
    "\n",
    "    def __init__(self, fileName: str = 'MecLPinput.xlsm'):\n",
    "        \"\"\" \n",
    "        Initializes the StemData object. \n",
    "        Reads data from the excel file and stores it in a dictionary.\n",
    "        A lazy implementation is not used due to the excessive load time of the Excel file.\n",
    "        \"\"\"\n",
    "\n",
    "        # self.path = os.path.join('C:\\\\GitHub\\\\23-4002-LPTool\\\\Data\\\\MockUI', fileName)\n",
    "        self.path = os.path.join('C:\\\\GitHub\\\\23-4002-LPTool\\\\Master', fileName)\n",
    "        if not os.path.exists(self.path):\n",
    "            print(f'Error: File {self.path} does not exist.')\n",
    "\n",
    "        self.data = self.read_excel_data()\n",
    "\n",
    "    def read_excel_data(self) -> dict[str, pd.DataFrame]:\n",
    "        \"\"\"\n",
    "        Reads data from the excel file and returns a dictionary with the data.\n",
    "        \"\"\"\n",
    "        # Read data from excel file\n",
    "        data = dict()  # Key is table name, value is dataframe.\n",
    "        xlapp = xw.App(visible=False, add_book=False)\n",
    "        try:\n",
    "            wb = xlapp.books.open(self.path, read_only=True)\n",
    "            data['LpTables'] = wb.sheets['LPspec'].range('tblLpTables').options(pd.DataFrame, expand='table', index=False).value\n",
    "            lpTables = data['LpTables']\n",
    "\n",
    "            for i in range(len(lpTables)):\n",
    "                tableName = lpTables.loc[i,'TableName']\n",
    "                sheetName = lpTables.loc[i,'SheetName']\n",
    "                rangeName = lpTables.loc[i,'RangeName']\n",
    "                useIndex = lpTables.loc[i,'UseIndex']\n",
    "                rowDim = int( lpTables.loc[i,'RowDim']) if useIndex else 0  \n",
    "                colDim = int(lpTables.loc[i,'ColDim'])\n",
    "                StemData._logger.info(f'Reading table {tableName} from sheet {sheetName} with range {rangeName}.')\n",
    "                # logger.info(f'UseIndex={useIndex}, RowDim = {rowDim}, ColDim = {colDim}.')\n",
    "                df = wb.sheets[sheetName].range(rangeName).options(pd.DataFrame, expand='table', index=rowDim, header=colDim).value\n",
    "                data[tableName] = df\n",
    "            wb.close()\n",
    "            \n",
    "        except Exception as e:\n",
    "            StemData._logger.exception(f'Error reading excel file {self.path}.', exc_info=True)\n",
    "        finally:\n",
    "            xlapp.quit()\n",
    "\n",
    "        return data\n",
    "\n",
    "class ModelData():\n",
    "\n",
    "    def __init__(self, fileName: str = 'MecLpMain.gdx'):\n",
    "        \"\"\" Initializes the ModelData object. \"\"\"\n",
    "        global logger\n",
    "        # self.path = os.path.join('C:\\\\GitHub\\\\23-4002-LPTool\\\\Data\\\\MockUI', fileName)\n",
    "        self.path = os.path.join('C:\\\\GitHub\\\\23-4002-LPTool\\\\Master', fileName)\n",
    "        if not os.path.exists(self.path):\n",
    "            raise ValueError(f'File {self.path} does not exist.')\n",
    "\n",
    "        self.Gsymbols = dict()  # Key is symbol name in lower case, value is GSymbolProxy instance.\n",
    "        self.data = dict()      # Key is symbol name in lower case, value is dataframe of records.\n",
    "        self.gw = gw.GdxWrapper(name='ModelData', pathFile=self.path, loggerName=logger.name)\n",
    "        return\n",
    "\n",
    "    def readSymbolAsDataFrame(self, symbolName: str, attrName: str = 'level') -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Reads data of a single GAMS symbol from the gdx file and returns a dataframe with the data.\n",
    "        \"\"\"\n",
    "        # Read symbol data from gdx file\n",
    "        gsym = gw.GSymbolProxy(symbolName, self.gw)\n",
    "        symbolData = self.gw.getRecords(symbolName.lower(), attrName)\n",
    "        if symbolData is None:\n",
    "            return None\n",
    "        \n",
    "        self.Gsymbols[symbolName.lower()] = gsym\n",
    "        self.data[symbolName.lower()] = symbolData\n",
    "\n",
    "        return symbolData\n",
    "\n",
    "    def __getitem__(self, symbolName: str) -> pd.DataFrame:\n",
    "        \"\"\" Returns the dataframe with the given key. Lazy implementation.\"\"\"\n",
    "        # See: https://www.kdnuggets.com/2023/03/introduction-getitem-magic-method-python.html\n",
    "        \n",
    "        if symbolName.lower() not in self.Gsymbols:\n",
    "            symbolData = self.readSymbolAsDataFrame(symbolName)\n",
    "            if symbolData is None:\n",
    "                logger.error(f'Symbol of name {symbolName} was not found.')\n",
    "                return None\n",
    "            self.data[symbolName] = symbolData\n",
    "\n",
    "        return self.data[symbolName.lower()]\n",
    "    \n",
    "def createPivot(dfRecs: pd.DataFrame, indexName: str, columnNames: list[str], valueName: str,\n",
    "                fillna: bool = True, createTimeColumn: bool = False, timeVector: list[float] = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Creates a pivot table from a DataFrame of records e.g. of a GAMS symbol like parameter, variable, equation.\n",
    "    Each column of dfRecs holds the values of a defining dimension of the symbol.\n",
    "    One column holds the attribute of the symbol e.g. value, level, marginal, lower, upper.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dfRecs : pd.DataFrame\n",
    "        Holds the records part of which will be used to compose the pivot table\n",
    "    indexName : str\n",
    "        Name of the column in dfRecs that should be index of the pivot table.\n",
    "    columnNames : list[str]\n",
    "        List of names of columns in dfRecs to constitute the columns of the pivot table.\n",
    "        If columnNames has two or more members, the columns of the pivot table will be a \n",
    "        multiindex i.e. a tuple of each dimension's member value (name).\n",
    "    valueName : str\n",
    "        Name of the column in dfRecs whose values will fill the body of the pivot table.\n",
    "    fillna : boolean, optional\n",
    "        If True (default), NaN-values will be converted to zeros.\n",
    "    createTimeColumn : boolean, optional\n",
    "        If True (default) and index of pivot the column of name 'tt', the numeric part of \n",
    "        the index values will be converted to integers and stored in a new column named 'time',\n",
    "        and the entire pivot table sorted ascendingly by this column.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        Either one of indexName, columnNames or valueName was not found in dfRecs.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pivot : DataFrame\n",
    "        The pivot table\n",
    "\n",
    "    \"\"\"\n",
    "    if indexName is not None and not indexName in dfRecs.columns:\n",
    "        raise ValueError(f'{indexName=} not found in columns of DataFrame dfRecs')\n",
    "    \n",
    "    for col in columnNames:\n",
    "        if not col in dfRecs.columns:\n",
    "            raise ValueError(f'Column {col=} not found in columns of DataFrame dfRecs')\n",
    "    \n",
    "    if not valueName in dfRecs.columns:\n",
    "        raise ValueError(f'{valueName=} not found in columns of DataFrame dfRecs')\n",
    "    \n",
    "    pivot = dfRecs.pivot(index=indexName, columns=columnNames, values=valueName)\n",
    "    \n",
    "    if fillna:\n",
    "        pivot = pivot.fillna(0.0)\n",
    "        \n",
    "    if createTimeColumn:\n",
    "        # Assuming the index of pivot has members of kind 't'nnnn where n is a digit.\n",
    "        if pivot.index.name != 'tt':\n",
    "            raise ValueError(f'Pivot must have index of name \"tt\", but \"{pivot.index.name}\" was found')\n",
    "            \n",
    "        if timeVector is None:\n",
    "            pivot['time'] = [int(tt[1:]) for tt in pivot.index]\n",
    "        else:\n",
    "            pivot['time'] = [timeVector[int(tt[1:]) - 1] for tt in pivot.index]\n",
    "\n",
    "        pivot = pivot.sort_values(by=['time'])\n",
    "    \n",
    "    return pivot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classes and methods to execute the GAMS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import class JobSpec from file JobSpec.py located in folder ../App/Engine\n",
    "from jobSpec import JobSpec\n",
    "from JobLib import CoreData \n",
    "\n",
    "parms = JobSpec.getDefaultMasterParms()\n",
    "parms = JobSpec.getDefaultMasterParms()\n",
    "jobSpec = JobSpec('name', 'desc', parms)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from Engine.JobSpec import JobSpec\n",
    "from Engine.JobLib import CoreData \n",
    "\n",
    "def time2int(time: datetime) -> int:\n",
    "    \"\"\" Converts a datetime object to an integer of kind 't'nnnn. \"\"\"\n",
    "    return int(time.strftime('%Y%m%d%H'+'00'))\n",
    "\n",
    "def setup(jobSpec: JobSpec, rootDir, logger) -> None:\n",
    "    \"\"\" Sets up the model prior to execution. \"\"\"\n",
    "\n",
    "    core = CoreData('None', rootDir, logger) \n",
    "\n",
    "    # Copy model files to the working directory.\n",
    "    core.copyInputFiles(copyAllFiles=True)\n",
    "    core.openExcelInputFile(visible=True)\n",
    "\n",
    "    # Set master parameters of the model. Use master scenario 2 (default).\n",
    "    core.setDefaultParms(2, 0, 0, 0, 0, 0)\n",
    "    for key, value in jobSpec.masterParms.items():\n",
    "        core.setParmMaster(key, value)\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootDir = 'C:\\\\GitHub\\\\23-4002-LPTool'\n",
    "\n",
    "allPlants = [   'MaNVak', 'MaVak', 'HoNVak', 'StVak', 'MaCool', 'MaCool2', 'MaAff1', 'MaAff2', 'MaBio', 'MaEk', 'MaNbk', 'MaNbKV', 'MaNEk', 'MaNhpAir', 'MaNhpPtX', \n",
    "                'HoNEk', 'HoNFlis', 'HoNhpAir', 'HoNhpArla', 'HoNhpBirn', 'HoNhpSew', 'HoGk', 'HoOk', \n",
    "                'StEk', 'StNEk', 'StNFlis', 'StNhpAir', 'StGk', 'StOk']\n",
    "\n",
    "activePlants = ['MaNVak', 'MaVak', 'StVak', 'MaCool', 'MaCool2', 'MaAff1',\n",
    "                'MaBio', 'MaEk', 'MaNbk', 'MaNhpAir',\n",
    "                'HoNhpBirn', 'HoNhpSew', 'HoGk', 'HoOk', \n",
    "                'StEk', 'StGk', 'StOk']\n",
    "\n",
    "jobSpec = JobSpec(\n",
    "        timeStart    = datetime.fromisoformat('2024-01-09'),     # Start time of model planning horizon.\n",
    "        duration     = 2 * 24,           # Duration [hour] of model planning horizon.\n",
    "        hourBegin    = 577,              # Hour of day when historical data interval starts.\n",
    "        resolBid     = 60,               # Resolution of bid day in minutes.\n",
    "        resolDefault = 60,               # Resolution of other days in minutes.\n",
    "        activePlants = activePlants      # List of active plants.\n",
    ")\n",
    "\n",
    "# setup(jobSpec, rootDir, logger)\n",
    "\n",
    "core = CoreData('m01s01u00r00f00', rootDir, logger) \n",
    "\n",
    "# Copy model files to the working directory.\n",
    "core.copyInputFiles(copyAllFiles=True)\n",
    "core.openExcelInputFile(visible=True)\n",
    "\n",
    "# Set master parameters of the model. Use master scenario 2 (default).\n",
    "core.setDefaultParms(2, 0, 0, 0, 0, 0)\n",
    "core.setParmMaster('OnUGlobalScen.HourBegin',             jobSpec.hourBegin)\n",
    "# core.setParmMaster('OnUGlobalScen.HourEnd',               jobSpec.hourEnd)\n",
    "core.setParmMaster('OnUGlobalScen.TimestampStart',        jobSpec.timeStart.strftime('%Y%m%d%H'+'00'))\n",
    "core.setParmMaster('OnUGlobalScen.DurationPeriod',        jobSpec.DurationPeriod)\n",
    "core.setParmMaster('OnUGlobalScen.TimeResolutionDefault', jobSpec.resolDefault)\n",
    "core.setParmMaster('OnUGlobalScen.TimeResolutionBid',     jobSpec.resolBid)\n",
    "\n",
    "for plant in jobSpec.activePlants:\n",
    "        core.setParmMaster(f'OnUGlobalScen.{plant}', 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classes and methods to read GAMS model results from gdx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = setupLogger('LpMockUI')\n",
    "\n",
    "#region Reading data\n",
    "\n",
    "readStemData = False\n",
    "readModelData = True\n",
    "\n",
    "if readStemData or readModelData:\n",
    "\n",
    "    tbegin = time.perf_counter_ns()\n",
    "    if readStemData:\n",
    "        # Create StemData object\n",
    "        logger.info('Reading StemData.')\n",
    "        stemData = StemData()\n",
    "        data = stemData.data\n",
    "\n",
    "    tend0 = time.perf_counter_ns()\n",
    "    print(f'Elapsed time reading stem data: {(tend0-tbegin)/1e9:.4f} seconds.')\n",
    "\n",
    "    if readModelData:\n",
    "        # Create ModelData object\n",
    "        modelData = ModelData()\n",
    "        symbolNames = ['u', 'upr', 'vak', 'OnUGlobal', 'TimeResol', \\\n",
    "                    'Qf_L', 'QTf', 'PfNet', 'FuelQty', 'QfDemandActual_L', 'EVak_L', \\\n",
    "                        'FuelCost', 'TotalCostU', 'TotalTaxUpr', 'StatsU', 'StatsTax']\n",
    "        for symbolName in symbolNames:\n",
    "            # logger.info(f'Reading symbol {symbolName}.')\n",
    "            dfQf_Lcumcum = modelData[symbolName]\n",
    "            # print(df)\n",
    "\n",
    "    tend1 = time.perf_counter_ns()\n",
    "    print(f'Elapsed time reading model data: {(tend1-tend0)/1e9:.4f} seconds.')\n",
    "\n",
    "    # for symbolName in symbolNames:\n",
    "    #     logger.info(f'Retrieving symbol {symbolName}.')\n",
    "    #     df = modelData[symbolName]\n",
    "\n",
    "    tend2 = time.perf_counter_ns()\n",
    "    print(f'Elapsed time in total: {(tend2-tbegin)/1e9:.4f} seconds.')\n",
    "\n",
    "#endregion Reading data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#region Extracting data to show\n",
    "\n",
    "# What is the reference for timestamps in the model? \n",
    "# Is it the time of the first record in the model?\n",
    "# Convention: Timestamp represents the start of the time interval hence the first record is at time 0.\n",
    "\n",
    "if readModelData:\n",
    "    # Pick available plants using the u symbol and the OnUGlobal symbol\n",
    "    dfTimeResol = modelData['TimeResol']\n",
    "    timeIncr = (dfTimeResol['level'] / 60).to_numpy()\n",
    "    timeVec = np.cumsum(timeIncr) - timeIncr[0]\n",
    "    \n",
    "    dfU = modelData['u']\n",
    "    dfOnUGlobal = modelData['OnUGlobal']\n",
    "    uAvail = dfOnUGlobal['u'].to_list()\n",
    "    dfUpr = modelData['upr']\n",
    "\n",
    "    # Remove columns of dfUpr that are not available\n",
    "    dfUpr = dfUpr[dfUpr['u'].isin(uAvail)]\n",
    "    orderU = ['MaNVak', 'MaVak', 'HoNVak', 'StVak', 'MaCool', 'MaCool2', 'MaAff1', 'MaAff2', 'MaBio', 'MaEk', 'MaNbk', 'MaNbKV', 'MaNEk', 'MaNhpAir', 'MaNhpPtX', \n",
    "        'HoNEk', 'HoNFlis', 'HoNhpAir', 'HoNhpArla', 'HoNhpBirn', 'HoNhpSew', 'HoGk', 'HoOk', \n",
    "        'StEk', 'StNEk', 'StNFlis', 'StNhpAir', 'StGk', 'StOk']\n",
    "\n",
    "    # Setup the display order of plants.\n",
    "    orderU = [u for u in orderU if u in uAvail]\n",
    "    plantGroups = {'Ma': 'BHP', 'Ho': 'Holstebro', 'St': 'Struer'}\n",
    "\n",
    "\n",
    "    # Fetch the records of Qf_L and create a pivot table\n",
    "    dfQf_LRecs = modelData['Qf_L']\n",
    "    # print(dfQf_LRecs.head())\n",
    "\n",
    "    #region Abandoned code working on records of Qf_L\n",
    "    # df = dfQf_LRecs.copy(deep=True)\n",
    "    # df['time'] = [timeVec[int(tt[1:]) - 1] for tt in df.tt]\n",
    "    # # df = df.sort_values(by=['time'])\n",
    "    # # print(df.head())\n",
    "    # # print(timeVec)\n",
    "    # # print(timeIncr)\n",
    "\n",
    "    # # Drop any row of df where the value of the column 'u' is not in uAvail\n",
    "    # df = df[df['u'].isin(uAvail)]\n",
    "\n",
    "    # # Also, replace values of df that are equal to 1E-14 with zero. The value 1E-14 is assigned within the GAMS model to ensure filled-in records.  \n",
    "    # df = df.replace(1E-14, 0.0)\n",
    "    # # print(df.head(20))\n",
    "\n",
    "    # orderU = ['MaNVak', 'MaVak', 'HoNVak', 'StVak', 'MaCool', 'MaCool2', 'MaAff1', 'MaAff2', 'MaBio', 'MaEk', 'MaNbk', 'MaNbKV', 'MaNEk', 'MaNhpAir', 'MaNhpPtX', \n",
    "    #           'HoNEk', 'HoNFlis', 'HoNhpAir', 'HoNhpArla', 'HoNhpBirn', 'HoNhpSew', 'HoGk', 'HoOk', \n",
    "    #           'StEk', 'StNEk', 'StNFlis', 'StNhpAir', 'StGk', 'StOk']\n",
    "    # orderU = [u for u in orderU if u in uAvail]\n",
    "    # # print(orderU)\n",
    "\n",
    "    # plantGroups = {'Ma': 'BHP', 'Ho': 'Holstebro', 'St': 'Struer'}\n",
    "    # df['plantGroup'] = [plantGroups[u[:2]] for u in df['u']]\n",
    "    # # print(df.head(20))\n",
    "\n",
    "    # # Drop any row of df where the value of the column 'u' contains Cool. Cooled heat is not delivered to the district heating system.\n",
    "    # df = df[~df['u'].str.contains('Cool')]\n",
    "    # print(df.head(20))  \n",
    "\n",
    "    # # Extract unique values of the column 'u' and sort them according to the order in orderU.\n",
    "    # uUnique = df['u'].unique()\n",
    "    # uUnique = [u for u in orderU if u in uUnique]\n",
    "    # # print(f'{uUnique=}')\n",
    "\n",
    "    # # # Sort df according to the order in column time, next to the order of orderU.\n",
    "    # # df = df.sort_values(by=['time', 'u'])\n",
    "    #endregion Abandoned code working on records of Qf_L\n",
    "\n",
    "    # print(timeVec)\n",
    "    print(dfQf_LRecs.head(20))\n",
    "    dfQf_Lx = createPivot(dfQf_LRecs, indexName='tt', columnNames=['u'], valueName='level', createTimeColumn=True, timeVector=timeVec)\n",
    "    \n",
    "    # dfQf_Lavail nov contains a column name 'time' and a column for each plant that is available. Dimension 'tt' is used as index.\n",
    "    # Pick only values of available production plants. \n",
    "    # Also, replace values of dfQf_Lavail that are less than 1E-12 with zero. The value 1E-14 is assigned within the GAMS model to ensure filled-in records.\n",
    "    dfQf_L = dfQf_Lx[['time'] + uAvail]   # Pick only columns of available plants and the time column.\n",
    "    # dfQf_L = dfQf_L.mask(dfQf_L.loc[:,:] < 1E-12 ,0.0, inplace=False)\n",
    "    dfQf_L = dfQf_L.replace(1E-14, 0.0)\n",
    "\n",
    "\n",
    "    # # If any column of dfQf_Lavail ends with 'Cool', reverse the sign of the column values. Cooled heat is not delivered to the district heating system.\n",
    "    for col in dfQf_L.columns:\n",
    "        if 'Cool' in col:\n",
    "            dfQf_L.loc[:,col] = -dfQf_L.loc[:,col] \n",
    "\n",
    "    # Create a column in dfQf_L that holds the timestamp composed of the now plus the time column.\n",
    "    timeOffset = datetime.fromisoformat('2024-01-08 00:00:00')\n",
    "    dfQf_L['timestamp'] = [timeOffset + timedelta(hours=t) for t in dfQf_L['time']]\n",
    "\n",
    "    # Sort columns of dfQf_L according to orderU and add the time column at the end.\n",
    "    dfQf_L = dfQf_L[['time', 'timestamp'] + orderU]\n",
    "\n",
    "    print(dfQf_L.head(20))\n",
    "\n",
    "#endregion Extracting data to show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plotly Express line (and scatter) plots have no option for stacking series. Therefore, the dataframe must be transformed.\n",
    "# Create a dataframe from dfQf_L where each column is the sum of itself and the previous column.\n",
    "# The first column is not changed and columns tt and time are not included in the summation.\n",
    "# The result is a dataframe with the same dimensions as dfQf_L, but where each column is the sum of itself and all previous columns of dfQf_L.\n",
    "\n",
    "def createStackedDf(df: pd.DataFrame, columns: list[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Creates a dataframe from df where each column contained in columns is the sum of itself and the previous column.\n",
    "    Columns not in colums are not included in the summation.\n",
    "    The result is a dataframe with the same dimensions as df, but where each column is the sum of itself and all previous columns of df.\n",
    "    df: dataframe holding the data to be transformed. This dataframe is not changed.\n",
    "    columns: list of column names to be included in the summation in the order they should appear in the result.\n",
    "\n",
    "    \"\"\"\n",
    "    dfCum = df.copy()\n",
    "    for i in range(1, len(columns)):\n",
    "        dfCum[columns[i]] = dfCum[columns[i]] + dfCum[columns[i-1]]\n",
    "\n",
    "    return dfCum\n",
    "\n",
    "\n",
    "dfQf_Lcum = createStackedDf(dfQf_L, orderU)\n",
    "print(f'df.head:\\n{dfQf_Lcum.head(2)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#region Setting up user interface\n",
    "\n",
    "# App layout\n",
    "\n",
    "# https://plotly.com/python-api-reference/\n",
    "\n",
    "useStacked = False\n",
    "\n",
    "df = dfQf_Lcum if useStacked else dfQf_L\n",
    "titlePrefix = 'Akkum. varmeleverancer' if useStacked else 'Varmeproduktion'\n",
    "# Drop columns containing Vak and Cool\n",
    "df = df.drop(columns=[col for col in df.columns if 'Cool' in col])\n",
    "# df = df.drop(columns=[col for col in df.columns if 'Vak' in col])\n",
    "orderUlocal = [u for u in orderU if u in df.columns]\n",
    "print(f'{orderUlocal=}')\n",
    "\n",
    "# Plotly templates: https://plotly.com/python/templates/\n",
    "# Plotly hovering: https://plotly.com/python/hover-text-and-formatting/\n",
    "\n",
    "fig = px.line(df, \n",
    "            x=\"timestamp\", \n",
    "            y=orderUlocal, \n",
    "            line_shape='hv',\n",
    "            title=f'<b>{titlePrefix} fra {timeOffset:%Y-%m-%d}</b>',\n",
    "            template='ggplot2',\n",
    "            width=1200,\n",
    "            height=15*len(df)\n",
    "            )  \n",
    "\n",
    "fig.layout.xaxis.title = 'Tid'\n",
    "fig.layout.yaxis.title = f'Varmeproduktion [MWh/h]'\n",
    "fig.layout.hovermode = 'closest'\n",
    "fig.layout.legend.title = '<b>Anlæg</b>'\n",
    "fig.show()\n",
    "\n",
    "\n",
    "# https://plotly.com/python-api-reference/generated/plotly.graph_objects.Figure.html\n",
    "\n",
    "pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Dash(__name__)\n",
    "\n",
    "df = px.data.gapminder()\n",
    "print(f'df.head: \\n{df.head(10)}')\n",
    "\n",
    "range_slider = dcc.RangeSlider(\n",
    "    value=[1987, 2007],\n",
    "    step=5,\n",
    "    marks={i: str(i) for i in range(1952, 2012, 5)},\n",
    ")\n",
    "\n",
    "dtable = dash_table.DataTable(\n",
    "    columns=[{\"name\": i, \"id\": i} for i in sorted(df.columns)],\n",
    "    sort_action=\"native\",\n",
    "    page_size=10,\n",
    "    style_table={\"overflowX\": \"auto\"},\n",
    ")\n",
    "\n",
    "download_button = html.Button(\"Download Filtered CSV\", style={\"marginTop\": 20})\n",
    "download_component = dcc.Download()\n",
    "\n",
    "app.layout = html.Div(\n",
    "    [\n",
    "        html.H2(\"Gapminder data filtered download\", style={\"marginBottom\": 20}),\n",
    "        download_component,\n",
    "        range_slider,\n",
    "        download_button,\n",
    "        dtable,\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output(dtable, \"data\"),\n",
    "    Input(range_slider, \"value\"),\n",
    ")\n",
    "def update_table(slider_value):\n",
    "    if not slider_value:\n",
    "        return dash.no_update\n",
    "    dff = df[df.year.between(slider_value[0], slider_value[1])]\n",
    "    return dff.to_dict(\"records\")\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output(download_component, \"data\"),\n",
    "    Input(download_button, \"n_clicks\"),\n",
    "    State(dtable, \"derived_virtual_data\"),\n",
    "    prevent_initial_call=True,\n",
    ")\n",
    "def download_data(n_clicks, data):\n",
    "    dff = pd.DataFrame(data)\n",
    "    return dcc.send_data_frame(dff.to_csv, \"filtered_csv.csv\")\n",
    "\n",
    "app.run(mode='inline', port=8056, debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the app\n",
    "df = dfQf_L\n",
    "cols = [c for c in df.columns if c in uAvail]\n",
    "dfShort = df.copy(deep=True)\n",
    "for c in cols:\n",
    "    dfShort[c] = df[c].apply(lambda x: round(x, 2))\n",
    "\n",
    "print(dfShort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def roundTable(df: pd.DataFrame, cols: list[str]) -> pd.DataFrame:\n",
    "    dfShort = df.copy(deep=True)\n",
    "    for c in cols:\n",
    "        dfShort[c] = df[c].apply(lambda x: round(x, 2))\n",
    "\n",
    "    return dfShort\n",
    "\n",
    "plantGroups = {'Ma': 'BHP', 'Ho': 'Holstebro', 'St': 'Struer'}\n",
    "orderUlocal = [u for u in orderU if u in df.columns]\n",
    "df = dfQf_Lcum if useStacked else dfQf_L\n",
    "df = df[['timestamp'] + orderUlocal]\n",
    "dfRound = roundTable(df, cols=[c for c in df.columns if c in uAvail])\n",
    "dfRound['timestamp'] = dfRound['timestamp'].apply(lambda x: x.strftime('%Y-%m-%d %H:%M'))\n",
    "print(dfRound.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8556/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x25bac8a5110>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "app = Dash(__name__, use_pages=False, external_stylesheets=[dbc.themes.MORPH])\n",
    "\n",
    "# App layout\n",
    "#region App layout timeseries\n",
    "# app.layout = html.Div(\n",
    "#     [\n",
    "#         html.H4(\"Forsyningsselskabets varmeproduktion\"),\n",
    "#         # html.P(\"Anlæg: \"),\n",
    "#         # dcc.Checklist(\n",
    "#         #     id=\"plants\",\n",
    "#         #     options=orderU,\n",
    "#         #     value=orderU,\n",
    "#         #     inline=True,\n",
    "#         # ),\n",
    "#         html.P(\"Gruppering: \"),\n",
    "#         dcc.RadioItems(\n",
    "#             id=\"grouping\",\n",
    "#             options=[\"Grundlast\", \"SR\", \"Ingen\"],\n",
    "#             value=\"Ingen\",\n",
    "#             inline=True,\n",
    "#         ),\n",
    "#         dbc.Label('Submit'), html.Br(),\n",
    "#         dbc.Button(\"Submit\", id='buttonRun'),\n",
    "#         dbc.RadioItems(options=[{'label': 'Unstacked', 'value': 1}, {'label': 'Stacked', 'value': 2}], value=1, id='radio'),\n",
    "#         dcc.Graph(id=\"graph\"),\n",
    "#     ]\n",
    "# )\n",
    "#endregion App layout timeseries\n",
    "\n",
    "checklist = dbc.Checklist(options=plantGroups, value=plantGroups.keys(), inline=True, id='selPlantGroups')\n",
    "\n",
    "dtable = dash_table.DataTable(\n",
    "    columns=[{\"name\": i, \"id\": i} for i in sorted(df.columns)],\n",
    "    data = dfRound.to_dict(\"records\"),\n",
    "    page_size=10,\n",
    "    style_table={\"fontSize\": 12, \"overflowX\": \"auto\"},\n",
    ")\n",
    "\n",
    "download_button = dbc.Button(\"Download Filtered Table as CSV\", style={\"marginTop\": 20})\n",
    "download_component = dcc.Download()\n",
    "\n",
    "def download_data(n_clicks, data):\n",
    "    dff = pd.DataFrame(data)\n",
    "    return dcc.send_data_frame(dff.to_csv, \"filtered_csv.csv\")\n",
    "\n",
    "\n",
    "#region App layout \n",
    "app.layout = html.Div(\n",
    "    [\n",
    "        dbc.Row([\n",
    "        html.P(html.H1(\"App Header\", style={'fontSize': '18', 'textAlign': 'center'})),\n",
    "        html.Hr(style={'border': '2px solid black'}),\n",
    "        ]),\n",
    "        dbc.Row([\n",
    "            dbc.Col(id='nav_bar', lg=2, children=['Nav bar']),\n",
    "            dbc.Col([\n",
    "                dbc.Tabs([\n",
    "                    dbc.Tab([\n",
    "                        html.Br(),\n",
    "                        html.H4(\"Forsyningsselskabets varmeproduktion\"),\n",
    "                        # dbc.Label('Submit'), html.Br(),\n",
    "                        dbc.Button(\"Submit\", id='buttonRun'),\n",
    "                        dbc.RadioItems(options=[{'label': 'Unstacked', 'value': 0}, {'label': 'Stacked', 'value': 1}], value=0, id='radio'),\n",
    "                        dcc.Graph(id=\"graph\"),\n",
    "                        ], label='Timeseries'),\n",
    "\n",
    "                    dbc.Tab([\n",
    "                        html.Ul([\n",
    "                            html.Br(),\n",
    "                            html.Li('Number of Economies: 170'),\n",
    "                            html.Li('Temporal Coverage: 1974 - 2019'),\n",
    "                            html.Li('Update Frequency: Quarterly'),\n",
    "                            html.Li('Last Updated: March 18, 2020'),\n",
    "                            html.Li([\n",
    "                                'Source: ',\n",
    "                                html.A('https://datacatalog.worldbank.org/dataset/poverty-and-equity-database',\n",
    "                                        href='https://datacatalog.worldbank.org/dataset/poverty-and-equity-database')\n",
    "                            ])\n",
    "                        ])\n",
    "                    ], label='Intro'),\n",
    "                    \n",
    "                    dbc.Tab([\n",
    "                        html.Br(),\n",
    "                        html.P('Her specificeres lastplanlægningen', style={'textAlign': 'left'})\n",
    "                    ], label='JobSpec'),\n",
    "\n",
    "                    dbc.Tab([\n",
    "                        html.Br(),\n",
    "                        html.P('Her vises resultater for lastplanen', style={'fontSize': '22', 'textAlign': 'left'}), \n",
    "                        html.Div([\n",
    "                            download_component,\n",
    "                            # checklist,\n",
    "                            download_button,\n",
    "                            dtable,\n",
    "                        ])                        \n",
    "                    ], label='ResultsTable'),\n",
    "                ])\n",
    "            ], lg=10)\n",
    "        ]),\n",
    "        dbc.Row([\n",
    "            html.Hr(style={'border': '2px solid black'}),\n",
    "            html.P(html.H1(\"App Footer\", style={'fontSize': '18', 'textAlign': 'center'})),\n",
    "        ]),\n",
    "    ], \n",
    "title='MockUI')\n",
    "\n",
    "#endregion App layout\n",
    "\n",
    "#region Callbacks\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"graph\", \"figure\"),\n",
    "    Input(\"radio\", \"value\")\n",
    ")\n",
    "def generate_chart(stacked):\n",
    "    df = dfQf_L.copy(deep=True)\n",
    "    # print(f'{plants=}')\n",
    "    # print(f'{grouping=}')\n",
    "    # uSelected = [u for u in orderU if u in plants]    # Sort according to predefined order.\n",
    "    # df = dfQf_L[['time'] + uSelected]\n",
    "    # Grouping ignored for now.\n",
    "    if stacked:\n",
    "        df = dfQf_Lcum\n",
    "    else: \n",
    "        df = dfQf_L\n",
    "\n",
    "    fig = px.line(df, \n",
    "            x=\"timestamp\", \n",
    "            y=orderUlocal, \n",
    "            line_shape='hv',\n",
    "            title=f'<b>{titlePrefix} fra {timeOffset:%Y-%m-%d}</b>',\n",
    "            template='ggplot2',\n",
    "            # width=1200,\n",
    "            # height=15*len(df)\n",
    "            )  \n",
    "\n",
    "    fig.layout.xaxis.title = 'Tid'\n",
    "    fig.layout.yaxis.title = f'Varmeproduktion [MWh/h]'\n",
    "    fig.layout.hovermode = 'closest'\n",
    "    fig.layout.legend.title = '<b>Anlæg</b>'\n",
    "    # fig.show()\n",
    "\n",
    "    return fig\n",
    "\n",
    "@app.callback(\n",
    "    Output(dtable, \"data\"),\n",
    "    Input(checklist, \"value\"),\n",
    ")\n",
    "def update_table(groups):\n",
    "    if not groups:\n",
    "        return dash.no_update\n",
    "    \n",
    "    dff = df[df['plantGroup'].isin(groups)]\n",
    "    cols = [c for c in dff.columns if c in uAvail]\n",
    "    for c in cols:\n",
    "        dff[c] = dff[c].apply(lambda x: round(x, 2))\n",
    "\n",
    "    # Replace timestamp with a string representation.\n",
    "    dff['timestamp'] = dff['timestamp'].apply(lambda x: x.strftime('%Y-%m-%d %H:%M'))\n",
    "    dff = dff[['timestamp'] + cols]\n",
    "\n",
    "    return dff.to_dict(\"records\")\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output(download_component, \"data\"),\n",
    "    Input(download_button, \"n_clicks\"),\n",
    "    State(dtable, \"derived_virtual_data\"),\n",
    "    prevent_initial_call=True,\n",
    ")\n",
    "def download_data(n_clicks, data):\n",
    "    dff = pd.DataFrame(data)\n",
    "    return dcc.send_data_frame(dff.to_csv, \"filtered_csv.csv\")\n",
    "\n",
    "#endregion Callbacks\n",
    "\n",
    "# Run the app\n",
    "app.run(mode='inline', port=8556)\n",
    "\n",
    "#endregion Setting up user interface\n",
    "pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
